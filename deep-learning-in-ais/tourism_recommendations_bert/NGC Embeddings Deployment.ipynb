{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277f5d4c-0e1c-47ce-82d0-c6f6b1a5bf8b",
   "metadata": {},
   "source": [
    "This Jupyter Notebook implements a BERT-based similarity model using MLflow for tracking, managing, and deploying the model. It loads a pre-trained BERT model, computes sentence embeddings, and retrieves the most similar sentences from a stored corpus based on cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c2be1-7e41-4318-b54b-74c0860ac597",
   "metadata": {},
   "source": [
    "# üîß Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b853f387-e023-46f8-bb01-a7db1049e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec\n",
    "\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nemo.collections.nlp.models.language_modeling import BERTLMModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba22c2a-f741-4a60-90e6-07a0fc5a97a6",
   "metadata": {},
   "source": [
    "# ‚¨áÔ∏è Downloading the Bert Large Uncased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2190db-3753-4eae-9520-4eed793e6b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-12 17:25:37 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo.\n",
      "[NeMo I 2025-03-12 17:25:37 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo\n",
      "[NeMo I 2025-03-12 17:25:37 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-12 17:25:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-03-12 17:25:48 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-12 17:25:48 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-12 17:25:48 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-12 17:25:49 save_restore_connector:249] Model BERTLMModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTLMModel(\n",
       "  (bert_model): BertEncoder(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (mlm_classifier): BertPretrainingTokenClassifier(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (mlp): MultiLayerPerceptron(\n",
       "      (layer0): Linear(in_features=1024, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mlm_loss): SmoothedCrossEntropyLoss()\n",
       "  (validation_perplexity): Perplexity()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERTLMModel.from_pretrained(model_name=\"bertlargeuncased\", strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85769bcb-33a8-4c27-8ede-f0f80d6d8785",
   "metadata": {},
   "source": [
    "# üèóÔ∏è Defining the BERT Similarity Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d71dcb-0ac2-4e8a-b03c-131600a9be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSimilarityModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        Load precomputed embeddings, corpus, and the pre-trained BERT model.\n",
    "        \"\"\"\n",
    "        # Load precomputed embeddings and corpus data\n",
    "        self.embeddings_df = pd.read_csv(context.artifacts['embeddings_df'])\n",
    "        self.corpus_df = pd.read_csv(context.artifacts['corpus_df'])\n",
    "        \n",
    "        # Load tokenizer for BERT\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "        \n",
    "        # Set device to GPU if available, otherwise use CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load pre-trained BERT model\n",
    "        self.bert_model = BERTLMModel.restore_from(context.artifacts['bert_model'], strict=False).to(self.device)\n",
    "    \n",
    "    def generate_query_embedding(self, query):\n",
    "        \"\"\"\n",
    "        Generate BERT embeddings for the input query.\n",
    "        \"\"\"\n",
    "        self.bert_model.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        # Tokenize the input query and move tensors to the selected device\n",
    "        encoded_input = self.tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        \n",
    "        # Get the model's output embedding\n",
    "        with torch.no_grad():\n",
    "            output = self.bert_model.bert_model(**encoded_input)\n",
    "        \n",
    "        # Return the [CLS] token embedding as a NumPy array\n",
    "        return output[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    def predict(self, context, model_input, params):\n",
    "        \"\"\"\n",
    "        Compute similarity between query and precomputed embeddings,\n",
    "        then return the top 5 most similar results.\n",
    "        \"\"\"\n",
    "        # Extract the query string from model input\n",
    "        query = model_input[\"query\"][0]\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.generate_query_embedding(query)\n",
    "        \n",
    "        # Compute cosine similarity between query and precomputed embeddings\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings_df.values)\n",
    "        \n",
    "        # Get indices of top 5 most similar results\n",
    "        top_indices = np.argsort(similarities[0])[::-1][:5]\n",
    "        \n",
    "        # Retrieve corresponding results from the corpus\n",
    "        results = self.corpus_df.iloc[top_indices].copy()\n",
    "        results.loc[:, 'Similarity'] = similarities[0][top_indices]\n",
    "        \n",
    "        # Return results as a dictionary\n",
    "        return results.to_dict(orient=\"records\")\n",
    "    \n",
    "    @classmethod\n",
    "    def log_model(cls, model_name, demo_folder=\"demo\"):\n",
    "        \"\"\"\n",
    "        Logs the model to MLflow with appropriate artifacts and schema.\n",
    "        \"\"\"\n",
    "        # Define input and output schema\n",
    "        input_schema = Schema([ColSpec(\"string\", \"query\")])\n",
    "        output_schema = Schema([\n",
    "            TensorSpec(np.dtype(\"object\"), (-1,), \"List of Pledges and Similarities\")\n",
    "        ])\n",
    "        params_schema = ParamSchema([ParamSpec(\"show_score\", \"boolean\", False)])\n",
    "        \n",
    "        # Define model signature\n",
    "        signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=params_schema)\n",
    "        \n",
    "        # Define necessary package requirements\n",
    "        requirements = [\"transformers==4.47.0\", \"huggingface-hub==0.20.2\"]\n",
    "        \n",
    "        # Log the model in MLflow\n",
    "        mlflow.pyfunc.log_model(\n",
    "            model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts={\n",
    "                \"embeddings_df\": \"data/embedded_data.csv\", \n",
    "                \"corpus_df\": \"data/CleanedData_Augmented.csv\",\n",
    "                \"bert_model\": \"/root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo\",            \n",
    "                \"demo\": demo_folder,\n",
    "            },\n",
    "            signature=signature,\n",
    "            pip_requirements=requirements\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0913e-b149-4ebf-9a6a-b3a2bb5676a0",
   "metadata": {},
   "source": [
    " # üìú Logging Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bbc01e-d831-4aea-bd80-fc20ff5576f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 17:25:49 INFO mlflow.tracking.fluent: Experiment with name 'BERT Similarity Model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run's Artifact URI: /phoenix/mlflow/667889996401907054/568df741a2b943c7b440da16232fa26d/artifacts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce82bd6002e24b92bbff5e5839525663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950086393df34cf69c5db941ae394b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af63a6720bcb4c0180a5f15e3f7aa4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3845fbef1c94a0daf0657d8de16a770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 17:25:54 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - transformers (current: 4.36.2, required: transformers==4.47.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "Successfully registered model 'BERT_Similarity'.\n",
      "Created version '1' of model 'BERT_Similarity'.\n"
     ]
    }
   ],
   "source": [
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(experiment_name=\"BERT Similarity Model\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=\"BERT_Similarity_Run\") as run:\n",
    "    # Print the artifact URI for reference\n",
    "    print(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # Log the BERT similarity model to MLflow\n",
    "    BERTSimilarityModel.log_model(model_name=\"BERT_Similarity\")\n",
    "\n",
    "    # Register the logged model in MLflow Model Registry\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/BERT_Similarity\", \n",
    "        name=\"BERT_Similarity\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686985b-88a6-4f23-9833-a8a13f4db282",
   "metadata": {},
   "source": [
    "# üì¶ Fetching the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49dc9da2-9f32-45b8-82a7-33c2c6b1427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-12 17:26:29 nemo_logging:349] /tmp/ipykernel_1730/3842674751.py:5: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "      model_metadata = client.get_latest_versions(\"BERT_Similarity\", stages=[\"None\"])\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Model Version: 1\n",
      "Model Signature: inputs: \n",
      "  ['query': string (required)]\n",
      "outputs: \n",
      "  ['List of Pledges and Similarities': Tensor('object', (-1,))]\n",
      "params: \n",
      "  ['show_score': boolean (default: False)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the \"BERT_Similarity\" model (not yet in a specific stage)\n",
    "model_metadata = client.get_latest_versions(\"BERT_Similarity\", stages=[\"None\"])\n",
    "latest_model_version = model_metadata[0].version  # Extract the latest model version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/BERT_Similarity/{latest_model_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "print(f\"Latest Model Version: {latest_model_version}\")\n",
    "print(f\"Model Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e98375-fb48-4065-a662-40b76096ed5f",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e35f73-8f63-49fe-b2ce-d898a7cca69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 17:26:29 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - transformers (current: 4.36.2, required: transformers==4.47.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "[NeMo W 2025-03-12 17:28:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-03-12 17:28:50 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-12 17:28:50 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-12 17:28:50 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-12 17:28:53 save_restore_connector:249] Model BERTLMModel was successfully restored from /phoenix/mlflow/667889996401907054/568df741a2b943c7b440da16232fa26d/artifacts/BERT_Similarity/artifacts/bertlargeuncased.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained BERT similarity model from MLflow\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/BERT_Similarity/{latest_model_version}\")\n",
    "\n",
    "# Define a sample query for testing\n",
    "query = \"Give me a resort budget vacation suggestion\"\n",
    "\n",
    "# Use the model to predict similar results based on the query\n",
    "result = model.predict({\"query\": [query]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec67eaa-b5ad-40f1-8ebe-6960450d9959",
   "metadata": {},
   "source": [
    "# üìú Displaying Results for the Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8a05ef-585c-49a5-a539-8114342a6b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïí‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïï\n",
      "‚îÇ    ‚îÇ Recommended Option                                                                                  ‚îÇ   Relevance Score ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ  0 ‚îÇ For a budget-friendly vacation, consider a resort with vacation options and cruise activities.      ‚îÇ          0.869171 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ  1 ‚îÇ For a budget-friendly vacation, consider a getaway with beach options and vacation activities.      ‚îÇ          0.863892 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ  2 ‚îÇ For a budget-friendly vacation, consider a getaway with hotel options and vacation activities.      ‚îÇ          0.862296 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ  3 ‚îÇ For a budget-friendly vacation, consider a reservation with beach options and mountains activities. ‚îÇ          0.861664 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ  4 ‚îÇ For a budget-friendly wildlife, consider a vacation with vacation options and holiday activities.   ‚îÇ          0.861548 ‚îÇ\n",
      "‚ïò‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïõ\n"
     ]
    }
   ],
   "source": [
    "# Convert the result into a pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Drop unnecessary columns if needed\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Topic\"], errors=\"ignore\")\n",
    "\n",
    "# Rename columns for better readability\n",
    "df.rename(columns={\"Pledge\": \"Recommended Option\", \"Similarity\": \"Relevance Score\"}, inplace=True)\n",
    "\n",
    "# Display the DataFrame in a tabular format\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcd04f-c949-4fb3-871d-30f9da9ce495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
