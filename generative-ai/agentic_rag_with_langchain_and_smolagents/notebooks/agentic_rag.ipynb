{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50506e56-cafc-4a1d-bb78-331c3de332a7",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\"> Agentic RAG </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6eb2d-7bb4-467a-a304-19befe728409",
   "metadata": {},
   "source": [
    "This notebook showcases a **Hugging Face** model integrated with a **retriever tool**, enabling it to fetch and use relevant context dynamically when answering questions about **Z by HP AI Studio**.  \n",
    "\n",
    "The solution is primarily built using the **LangChain** and **SmolAgents** libraries, creating an agent capable of context-aware retrieval and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80756fd3-1455-480c-8704-4452df070b8c",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "- Imports\n",
    "- Configurations\n",
    "- Verify Assets\n",
    "- Load PDF File\n",
    "- Split Text\n",
    "- Embed Text\n",
    "- Define Retriever Tool\n",
    "- Create Agent\n",
    "- Run Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e893437-a9fa-4304-a39d-f17f1d96b625",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f2473-a563-4ae0-836f-1c440bd65ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb1b32-3587-4804-9794-3dc9abb2f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from smolagents import Tool, HfApiModel, ToolCallingAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b668eb-6464-4a7d-bba7-1b56e3fe4ecc",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6fcf6-90eb-42da-81eb-eba151d89d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31f32a-4648-4b08-9003-cf5dac7fb441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = logging.getLogger(\"notebook_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "                              datefmt=\"%Y-%m-%d %H:%M:%S\")  \n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ada8c2-db9b-4380-bd17-7d1a096e9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../data/AIStudioDoc.pdf\"\n",
    "TOKENIZER_NAME = \"thenlper/gte-small\"\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "HF_MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2449f35-c4e2-45bf-81c6-6035092b4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual Hugging Face API key\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dae700-4b96-4e28-b557-85bf9057c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Notebook execution started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eef0a6-fc25-4631-a517-f76607ee645d",
   "metadata": {},
   "source": [
    "# Load PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd579e5-f289-4761-9afa-a31ab9bf1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(PDF_PATH)\n",
    "\n",
    "print(\"Reading and extracting PDF content...\")\n",
    "source_docs = []\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        source_docs.append(Document(page_content=text, metadata={\"source\": f\"page_{i + 1}\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be5ace-6912-4d85-b418-29f4f0d4bcf0",
   "metadata": {},
   "source": [
    "# Split Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5c751-3aed-4712-9a9a-7bc8bc473fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting documents...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(TOKENIZER_NAME),\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "docs_processed = []\n",
    "unique_texts = {}\n",
    "for doc in tqdm(source_docs):\n",
    "    new_docs = text_splitter.split_documents([doc])\n",
    "    for new_doc in new_docs:\n",
    "        if new_doc.page_content not in unique_texts:\n",
    "            unique_texts[new_doc.page_content] = True\n",
    "            docs_processed.append(new_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96aafd-01fa-4c07-b5db-52da083c7e21",
   "metadata": {},
   "source": [
    "# Embed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6791d-bfea-45b6-9b5e-a8f7ded74e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embedding documents...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=docs_processed,\n",
    "    embedding=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cebdb3-18f7-46f9-931d-c61925f8dc4f",
   "metadata": {},
   "source": [
    "# Define Retriever Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11e046-36f1-431d-926b-ea611ff70204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Using semantic similarity, retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, vectordb: VectorStore, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "        docs = self.vectordb.similarity_search(query, k=7)\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [f\"===== Document {i} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b790bb3-871c-4d08-ba8e-831b7743f00c",
   "metadata": {},
   "source": [
    "# Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836cf61-d1c1-4da7-8012-3b01641e9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HfApiModel(HF_MODEL_NAME)\n",
    "retriever_tool = RetrieverTool(vectordb)\n",
    "agent = ToolCallingAgent(tools=[retriever_tool], model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2df9a-1352-448d-95b3-d2a5db1f1d49",
   "metadata": {},
   "source": [
    "# Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b4dc5-fb76-442f-a19b-3e6d9be0656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the Z by HP AI Studio?\"\n",
    "\n",
    "enhanced_question = f\"\"\"Using the information contained in your knowledge base, which you can access with the 'retriever' tool,\n",
    "give a comprehensive answer to the question below.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "If you cannot find information, do not give up and try calling your retriever again with different arguments!\n",
    "Make sure to have covered the question completely by calling the retriever tool several times with semantically different queries.\n",
    "Your queries should not be questions but affirmative form sentences: e.g. rather than \"What is the Z by HP AI Studio?\", query should be \"The Z by HP AI Studio is a platform...\".\n",
    "\n",
    "Question:\n",
    "{question}\"\"\"\n",
    "\n",
    "answer = agent.run(enhanced_question)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b07a1-657a-4b0e-a978-31a5c97f000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Notebook execution completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ab3f1-2cd7-4fa4-ae6c-943ed60ef32f",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**Z by HP AI Studio**](https://zdocs.datascience.hp.com/docs/aistudio/overview)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
