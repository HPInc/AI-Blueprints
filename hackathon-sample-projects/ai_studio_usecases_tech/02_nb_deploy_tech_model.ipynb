{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anHc00I2AtTi"
   },
   "source": [
    "## Tech Adoption Scenario\n",
    "\n",
    "Background: A technology company is implementing an AI-powered system to help product managers and marketing teams identify suitable users for targeted product recommendations. The company wants to move beyond basic demographic targeting to a more nuanced approach that can understand natural language queries and user characteristics holistically.\n",
    "\n",
    "Use Case: Product managers and marketers can use natural language to find users matching specific profiles or needs. For example, they might search for \"early adopters with high technical proficiency interested in smart home technology\" or \"budget-conscious users who prefer Android devices\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Overview\n",
    "\n",
    "This notebook demonstrates how to build and deploy a machine learning model that uses natural language processing to match tech user profiles with product managers' queries. The system leverages:\n",
    "\n",
    "1. **Sentence Transformers**: To convert both user profiles and natural language queries into semantic vector embeddings\n",
    "2. **MLflow**: For model packaging, versioning, and deployment\n",
    "3. **Semantic Search**: Using cosine similarity to find the most relevant user matches\n",
    "\n",
    "When deployed, product managers can simply type queries like \"Find users who are early adopters of smart home technology\" and get a list of the most relevant users without needing to construct complex database queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR9w8OAnAyM1"
   },
   "source": [
    "## Process Description\n",
    "\n",
    "This Tech User Similarity Model provides a semantic search capability over user profiles. It works by:\n",
    "\n",
    "Data Preparation: User data (demographics, tech preferences, adoption patterns) is processed and organized.\n",
    "\n",
    "Embedding Generation: The SentenceTransformer model converts user profiles into numerical embeddings (high-dimensional vectors) that capture semantic meaning.\n",
    "\n",
    "MLflow Deployment: The model, embeddings, and dataset are packaged and deployed using MLflow for reproducible inference.\n",
    "\n",
    "Query Processing: When a product manager enters a natural language query, it's converted to an embedding using the same model.\n",
    "\n",
    "Similarity Matching: The system calculates cosine similarity between the query embedding and all user embeddings to find the most similar users.\n",
    "\n",
    "Result Presentation: Top matching users are presented with their relevant information and similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2Qsxw9tBr3V"
   },
   "source": [
    "## Benefits\n",
    "\n",
    "Targeted Marketing: Identify users most likely to adopt new technologies based on their profile similarity to successful past campaigns.\n",
    "\n",
    "Product Development: Understand user segments and their technology preferences to guide product development.\n",
    "\n",
    "Cross-Selling Opportunities: Find users similar to those who have already adopted specific products.\n",
    "\n",
    "Natural Language Interface: Allows product managers to search users without needing complex SQL queries or predefined segments.\n",
    "\n",
    "Scalability: The system can handle millions of user profiles efficiently due to the vector-based search approach.\n",
    "\n",
    "This system bridges the gap between rich user data and actionable insights by providing an intuitive way to explore user segments and identify targeted opportunities for engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Implementation\n",
    "\n",
    "The following code implements the complete Tech User Similarity system. We'll start by importing necessary libraries and setting up our model environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 20:58:35.067628: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-04 20:58:35.352762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743800315.457535    1331 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743800315.489504    1331 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743800315.752758    1331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743800315.752788    1331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743800315.752789    1331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743800315.752790    1331 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 20:58:35.785151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Model settings - using sentence-transformers\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading\n",
    "\n",
    "First, we define a function to load our sentence transformer model, which will handle the semantic encoding of text. This model converts text into high-dimensional vectors where similar meanings are positioned closer together in the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Load the sentence-transformers model for embedding\"\"\"\n",
    "    print(f\"Loading SentenceTransformer model: {MODEL_NAME}\")\n",
    "    \n",
    "    # Set device to GPU if available, otherwise use CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "The core of our system is the `TechAdoptionSimilarityModel` class which:\n",
    "1. Loads pre-computed user embeddings and tech data\n",
    "2. Handles query encoding and similarity computation\n",
    "3. Formats results for display\n",
    "4. Includes MLflow integration for model deployment\n",
    "\n",
    "This class inherits from `mlflow.pyfunc.PythonModel` to make it deployable through MLflow's model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechAdoptionSimilarityModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load precomputed embeddings, tech data, and sentence-transformer model.\"\"\"\n",
    "        # Load precomputed embeddings\n",
    "        self.embeddings = np.load(context.artifacts['embeddings_path'])\n",
    "        \n",
    "        # Load tech dataset\n",
    "        self.user_data = pd.read_csv(context.artifacts['tech_dataset_path'])\n",
    "        \n",
    "        # Print diagnostics about the loaded data\n",
    "        print(f\"Loaded embeddings shape: {self.embeddings.shape}\")\n",
    "        print(f\"Loaded tech data shape: {self.user_data.shape}\")\n",
    "        \n",
    "        # Create user descriptions for reference\n",
    "        self.user_descriptions = []\n",
    "        for _, row in self.user_data.iterrows():\n",
    "            desc = (\n",
    "                f\"User ID: {row['user_id']}, \"\n",
    "                f\"Age: {row['age']}, \"\n",
    "                f\"Gender: {row['gender']}, \"\n",
    "                f\"Location: {row['location']}, \"\n",
    "                f\"Education: {row['education']}, \"\n",
    "                f\"Job Sector: {row['job_sector']}, \"\n",
    "                f\"Annual Income: ${row['annual_income']}, \"\n",
    "                f\"Adopter Category: {row['adopter_category']}, \"\n",
    "                f\"Tech Interest: {row['tech_interest']}, \"\n",
    "                f\"Technical Proficiency: {row['technical_proficiency']}\"\n",
    "            )\n",
    "            self.user_descriptions.append(desc)\n",
    "        \n",
    "        # Load model\n",
    "        self.model_name = MODEL_NAME\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "        \n",
    "        # Set device for model\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"SentenceTransformer model '{self.model_name}' loaded successfully\")\n",
    "\n",
    "    def generate_query_embedding(self, query):\n",
    "        \"\"\"Generate embedding for the input query\"\"\"\n",
    "        return self.model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"Find similar tech users based on semantic similarity to the query text\"\"\"\n",
    "        # Extract the query string from model input\n",
    "        try:\n",
    "            if hasattr(model_input, \"query\"):\n",
    "                if hasattr(model_input[\"query\"], \"iloc\") or hasattr(model_input[\"query\"], \"loc\"):\n",
    "                    query = model_input[\"query\"].iloc[0]\n",
    "                    if isinstance(query, list):\n",
    "                        query = query[0]\n",
    "                elif isinstance(model_input[\"query\"], list):\n",
    "                    query = model_input[\"query\"][0]\n",
    "                    if isinstance(query, list):\n",
    "                        query = query[0]\n",
    "                else:\n",
    "                    query = model_input[\"query\"]\n",
    "            else:\n",
    "                query = str(model_input)\n",
    "            \n",
    "            if not isinstance(query, str):\n",
    "                query = str(query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting query: {e}\")\n",
    "            print(f\"Model input structure: {type(model_input)}\")\n",
    "            print(f\"Model input content: {model_input}\")\n",
    "            query = \"\"\n",
    "        \n",
    "        print(f\"Processing query: '{query}'\")\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Extract parameters\n",
    "        top_n = params.get(\"top_n\", 5) if params else 5\n",
    "        \n",
    "        # Get initial candidates - get more than needed for boosting/reranking\n",
    "        query_embedding = self.generate_query_embedding(query)\n",
    "        similarities = cosine_similarity([query_embedding], self.embeddings)[0]\n",
    "        candidate_indices = np.argsort(similarities)[::-1][:min(top_n * 3, len(self.user_data))]\n",
    "        \n",
    "        # --- SCORE ADJUSTMENT LOGIC ---\n",
    "        # Create mappings for categorical values\n",
    "        proficiency_values = {\n",
    "            \"Very Low\": 1, \"Low\": 2, \"Moderate\": 3, \n",
    "            \"High\": 4, \"Very High\": 5\n",
    "        }\n",
    "        \n",
    "        adopter_values = {\n",
    "            \"Innovator\": 5, \"Early Adopter\": 4, \"Early Majority\": 3,\n",
    "            \"Late Majority\": 2, \"Laggard\": 1\n",
    "        }\n",
    "        \n",
    "        # Initialize boost array\n",
    "        sim_boost = np.zeros(len(candidate_indices))\n",
    "        \n",
    "        # 1. Technical proficiency boost (up to 0.3)\n",
    "        if any(term in query_lower for term in [\"high proficiency\", \"tech savvy\", \"technical users\", \n",
    "                                               \"advanced users\", \"experienced\", \"expert\"]):\n",
    "            print(\"Applying technical proficiency boost\")\n",
    "            prof_scores = []\n",
    "            for idx in candidate_indices:\n",
    "                user = self.user_data.iloc[idx]\n",
    "                prof = proficiency_values.get(user['technical_proficiency'], 0)\n",
    "                prof_scores.append(prof)\n",
    "            \n",
    "            prof_scores = np.array(prof_scores)\n",
    "            prof_boost = np.clip((prof_scores - 3) / 5, 0, 0.3)  # Up to 0.3 boost for high proficiency\n",
    "            sim_boost += prof_boost\n",
    "        \n",
    "        elif any(term in query_lower for term in [\"beginner\", \"novice\", \"new to tech\", \"low proficiency\"]):\n",
    "            print(\"Applying beginner-friendly boost\")\n",
    "            prof_scores = []\n",
    "            for idx in candidate_indices:\n",
    "                user = self.user_data.iloc[idx]\n",
    "                prof = proficiency_values.get(user['technical_proficiency'], 0)\n",
    "                prof_scores.append(prof)\n",
    "            \n",
    "            prof_scores = np.array(prof_scores)\n",
    "            # Boost for lower proficiency (reverse scale)\n",
    "            prof_boost = np.clip((3 - prof_scores) / 5, 0, 0.3)\n",
    "            sim_boost += prof_boost\n",
    "        \n",
    "        # 2. Adopter category boost (up to 0.3)\n",
    "        if any(term in query_lower for term in [\"early adopter\", \"innovator\", \"cutting edge\", \n",
    "                                               \"technology enthusiast\", \"first to adopt\"]):\n",
    "            print(\"Applying early adopter boost\")\n",
    "            adopter_scores = []\n",
    "            for idx in candidate_indices:\n",
    "                user = self.user_data.iloc[idx]\n",
    "                score = adopter_values.get(user['adopter_category'], 0)\n",
    "                adopter_scores.append(score)\n",
    "            \n",
    "            adopter_scores = np.array(adopter_scores)\n",
    "            adopter_boost = np.clip((adopter_scores - 2) / 5, 0, 0.3)  # Up to 0.3 boost for early adopters\n",
    "            sim_boost += adopter_boost\n",
    "        \n",
    "        elif any(term in query_lower for term in [\"mainstream user\", \"typical user\", \"average consumer\", \"late majority\"]):\n",
    "            print(\"Applying mainstream user boost\")\n",
    "            # Different mapping for mainstream users (Early/Late Majority get highest scores)\n",
    "            mainstream_values = {\n",
    "                \"Innovator\": 2, \"Early Adopter\": 3, \"Early Majority\": 5,\n",
    "                \"Late Majority\": 5, \"Laggard\": 2\n",
    "            }\n",
    "            \n",
    "            adopter_scores = []\n",
    "            for idx in candidate_indices:\n",
    "                user = self.user_data.iloc[idx]\n",
    "                score = mainstream_values.get(user['adopter_category'], 0)\n",
    "                adopter_scores.append(score)\n",
    "            \n",
    "            adopter_scores = np.array(adopter_scores)\n",
    "            adopter_boost = np.clip((adopter_scores - 2) / 5, 0, 0.3)\n",
    "            sim_boost += adopter_boost\n",
    "        \n",
    "        # 3. Income-based boost (up to 0.3)\n",
    "        if any(term in query_lower for term in [\"high income\", \"affluent\", \"premium\", \"high budget\", \n",
    "                                              \"luxury\", \"high-end\", \"wealthy\"]):\n",
    "            print(\"Applying high income boost\")\n",
    "            incomes = []\n",
    "            for idx in candidate_indices:\n",
    "                user = self.user_data.iloc[idx]\n",
    "                incomes.append(user['annual_income'])\n",
    "            \n",
    "            incomes = np.array(incomes)\n",
    "            # Boost higher incomes more (assume 75k is high income threshold)\n",
    "            income_boost = np.clip((incomes - 75000) / 100000, 0, 0.3)\n",
    "            sim_boost += income_boost\n",
    "        \n",
    "        elif any(term in query_lower for term in [\"budget\", \"affordable\", \"low cost\", \"inexpensive\", \n",
    "                                                \"cost sensitive\", \"economical\", \"value\"]):\n",
    "            print(\"Applying budget-conscious boost\")\n",
    "            incomes = []\n",
    "            for idx in candidate_indices:\n",
    "                user = self.user_data.iloc[idx]\n",
    "                incomes.append(user['annual_income'])\n",
    "            \n",
    "            incomes = np.array(incomes)\n",
    "            # For budget queries, boost LOWER incomes (below 50k)\n",
    "            income_boost = np.clip((50000 - incomes) / 50000, 0, 0.3) \n",
    "            sim_boost += income_boost\n",
    "        \n",
    "        # 4. Technology interest exact match boost (0.2 fixed boost)\n",
    "        common_tech_interests = [\"AI\", \"artificial intelligence\", \"machine learning\", \"IoT\", \n",
    "                               \"internet of things\", \"smart home\", \"VR\", \"virtual reality\",\n",
    "                               \"AR\", \"augmented reality\", \"mobile\", \"cloud\", \"gaming\", \n",
    "                               \"robotics\", \"automation\", \"cryptocurrency\", \"blockchain\", \n",
    "                               \"wearable\", \"smartphone\", \"5G\", \"cyber security\"]\n",
    "                               \n",
    "        for tech_term in common_tech_interests:\n",
    "            if tech_term.lower() in query_lower:\n",
    "                print(f\"Applying boost for '{tech_term}' interest match\")\n",
    "                for i, idx in enumerate(candidate_indices):\n",
    "                    user = self.user_data.iloc[idx]\n",
    "                    if tech_term.lower() in user['tech_interest'].lower():\n",
    "                        sim_boost[i] += 0.2  # Fixed boost for exact tech interest match\n",
    "        \n",
    "        # Apply the boost to similarity scores\n",
    "        for i, idx in enumerate(candidate_indices):\n",
    "            # Apply boost only to the candidates we're considering\n",
    "            similarities[candidate_indices[i]] += sim_boost[i]\n",
    "        \n",
    "        # Re-rank based on boosted scores\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "        \n",
    "        # Format results\n",
    "        predictions = []\n",
    "        for idx in top_indices:\n",
    "            user = self.user_data.iloc[idx]\n",
    "            info = self.user_descriptions[idx]\n",
    "            \n",
    "            result = {\n",
    "                'user_id': user['user_id'],\n",
    "                'User': info,\n",
    "                'Similarity': float(similarities[idx])\n",
    "            }\n",
    "            predictions.append(result)\n",
    "        \n",
    "        return {\"predictions\": predictions}\n",
    "    \n",
    "    @classmethod\n",
    "    def log_model(cls, model_name, embeddings_path, tech_dataset_path, demo_dir=None):\n",
    "        \"\"\"\n",
    "        Logs the model to MLflow with appropriate artifacts and schema.\n",
    "        \"\"\"\n",
    "        # Check if the files exist\n",
    "        for path in [embeddings_path, tech_dataset_path]:\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "        \n",
    "        # Print file sizes for information\n",
    "        emb_size = os.path.getsize(embeddings_path) / (1024 * 1024)\n",
    "        tech_size = os.path.getsize(tech_dataset_path) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"Embeddings file size: {emb_size:.2f} MB\")\n",
    "        print(f\"Tech dataset file size: {tech_size:.2f} MB\")\n",
    "        \n",
    "        # Simple input schema - just accepting a query string\n",
    "        input_schema = Schema([ColSpec(\"string\", \"query\")])\n",
    "        \n",
    "        # Output schema now matches the HTML expectation structure\n",
    "        output_schema = Schema([\n",
    "            TensorSpec(np.dtype(\"object\"), (-1,), \"predictions\")\n",
    "        ])\n",
    "        \n",
    "        # Parameters schema - include show_score to match HTML interface\n",
    "        params_schema = ParamSchema([\n",
    "            ParamSpec(\"top_n\", \"integer\", 5),\n",
    "            ParamSpec(\"show_score\", \"boolean\", True)\n",
    "        ])\n",
    "        \n",
    "        # Define model signature\n",
    "        signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=params_schema)\n",
    "        \n",
    "        # Define necessary package requirements - adding sentence-transformers\n",
    "        requirements = [\n",
    "            \"scikit-learn\",\n",
    "            \"pandas\",\n",
    "            \"numpy\",\n",
    "            \"tabulate\",\n",
    "            \"torch\",\n",
    "            \"transformers\",\n",
    "            \"sentence-transformers\"\n",
    "        ]\n",
    "        \n",
    "        # Define artifacts dictionary\n",
    "        artifacts = {\n",
    "            \"embeddings_path\": embeddings_path,\n",
    "            \"tech_dataset_path\": tech_dataset_path\n",
    "        }\n",
    "        \n",
    "        # Add demo directory to artifacts if provided and exists\n",
    "        if demo_dir and os.path.exists(demo_dir):\n",
    "            artifacts[\"demo\"] = demo_dir\n",
    "            \n",
    "        # Define metadata with demo template if demo directory is provided and has index.html\n",
    "        metadata = {}\n",
    "        if demo_dir and os.path.exists(os.path.join(demo_dir, \"index.html\")):\n",
    "            metadata[\"demo_template\"] = \"demo/index.html\"\n",
    "        \n",
    "        # Log the model in MLflow\n",
    "        mlflow.pyfunc.log_model(\n",
    "            model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts=artifacts,\n",
    "            signature=signature,\n",
    "            pip_requirements=requirements,\n",
    "            metadata=metadata\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Model Deployment\n",
    "\n",
    "The following function handles the MLflow experiment setup, model logging, and registration. \n",
    "MLflow is used to:\n",
    "- Track experiments and model versions\n",
    "- Package the model with its dependencies and artifacts\n",
    "- Register the model in the Model Registry for deployment\n",
    "- Store the UI components for interactive demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_to_mlflow():\n",
    "    # Set the MLflow experiment name\n",
    "    experiment_name = \"Tech Adoption Similarity\"\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "    print(f\"Experiment name: {experiment_name}\")\n",
    "    \n",
    "    # Check if demo directory exists and has index.html\n",
    "    demo_dir = \"demo\"\n",
    "    index_html_path = os.path.join(demo_dir, \"index.html\")\n",
    "    \n",
    "    if os.path.exists(index_html_path):\n",
    "        print(f\"Found UI at {index_html_path}, will include in model deployment\")\n",
    "    else:\n",
    "        print(f\"Warning: UI file not found at {index_html_path}\")\n",
    "        os.makedirs(demo_dir, exist_ok=True)\n",
    "        print(\"Creating demo directory...\")\n",
    "\n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=\"Tech_Adoption_Similarity_Run\") as run:\n",
    "        # Print the artifact URI for reference\n",
    "        print(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "        \n",
    "        # Log the tech adoption similarity model to MLflow\n",
    "        model_name = \"Tech_Adoption_Similarity\"\n",
    "        TechAdoptionSimilarityModel.log_model(\n",
    "            model_name=model_name,\n",
    "            embeddings_path=\"data/tech_embeddings.npy\",\n",
    "            tech_dataset_path=\"data/tech_adoption_dataset.csv\",\n",
    "            demo_dir=demo_dir if os.path.exists(demo_dir) else None\n",
    "        )\n",
    "\n",
    "        # Register the logged model in MLflow Model Registry\n",
    "        registered_model = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{run.info.run_id}/{model_name}\", \n",
    "            name=model_name\n",
    "        )\n",
    "        \n",
    "        # Get the version number of the registered model\n",
    "        version = registered_model.version\n",
    "        print(f\"Registered model: {model_name}\")\n",
    "        print(f\"Model version: {version}\")\n",
    "        \n",
    "        return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline\n",
    "\n",
    "The `find_similar_users` function demonstrates how to load our deployed model and use it for inference. This represents what would happen in a production environment when the model is called through an API or application interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(query, run_id=None, top_n=5):\n",
    "    \"\"\"\n",
    "    Find similar tech users for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query (e.g., \"Find users with high tech interest and early adoption patterns\")\n",
    "        run_id (str, optional): MLflow run ID. If None, uses the latest model version\n",
    "        top_n (int): Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Similar tech users\n",
    "    \"\"\"\n",
    "    if run_id:\n",
    "        # Load model from specific run\n",
    "        model_uri = f\"runs:/{run_id}/Tech_Adoption_Similarity\"\n",
    "    else:\n",
    "        # Get latest model version\n",
    "        client = MlflowClient()\n",
    "        model_metadata = client.get_latest_versions(\"Tech_Adoption_Similarity\", stages=[\"None\"])\n",
    "        latest_model_version = model_metadata[0].version\n",
    "        model_uri = f\"models:/Tech_Adoption_Similarity/{latest_model_version}\"\n",
    "    \n",
    "    # Load the model\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Prepare simple input data\n",
    "    input_data = {\"query\": [query]}\n",
    "    \n",
    "    # Run inference\n",
    "    result = model.predict(input_data)\n",
    "    \n",
    "    # Extract predictions array from the result\n",
    "    predictions = result.get(\"predictions\", [])\n",
    "    \n",
    "    # Convert to DataFrame for better display\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo\n",
    "\n",
    "The `run_demo` function shows a complete end-to-end demonstration, from model deployment to user search. This simulates how a product manager would interact with the system in a real environment.\n",
    "\n",
    "The demo covers:\n",
    "1. Model deployment to MLflow\n",
    "2. Running a sample query \n",
    "3. Displaying formatted results\n",
    "4. Error handling for failed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: Tech Adoption Similarity\n",
      "Found UI at demo/index.html, will include in model deployment\n",
      "Run's Artifact URI: /phoenix/mlflow/970250650912509670/79fc657690004b578f1081a812336067/artifacts\n",
      "Embeddings file size: 1.46 MB\n",
      "Tech dataset file size: 0.87 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1204f88394d74f06a78cdfc6e2db9208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ad3c7b44e44662aad60d434a623bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68b714c321642eab63eb504416eb0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Tech_Adoption_Similarity' already exists. Creating a new version of this model...\n",
      "Created version '31' of model 'Tech_Adoption_Similarity'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model: Tech_Adoption_Similarity\n",
      "Model version: 31\n",
      "Loaded embeddings shape: (1000, 384)\n",
      "Loaded tech data shape: (1000, 29)\n",
      "SentenceTransformer model 'sentence-transformers/all-MiniLM-L6-v2' loaded successfully\n",
      "Processing query: 'Find users with high tech interest who are early adopters of new technologies'\n",
      "Applying early adopter boost\n",
      "Applying boost for 'AR' interest match\n",
      "\n",
      "Query: Find users with high tech interest who are early adopters of new technologies\n",
      "\n",
      "Top similar tech users:\n",
      "╒═══════════╤══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╤══════════════╕\n",
      "│ user_id   │ User                                                                                                                                                                                                                                             │   Similarity │\n",
      "╞═══════════╪══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪══════════════╡\n",
      "│ TU0056    │ User ID: TU0056, Age: 68, Gender: Non-binary, Location: New York, NY, Education: High School, Job Sector: Technology, Annual Income: $200073.29, Adopter Category: Early Adopter, Tech Interest: Very High, Technical Proficiency: Intermediate  │     0.881492 │\n",
      "├───────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ TU0016    │ User ID: TU0016, Age: 53, Gender: Non-binary, Location: Boston, MA, Education: Bachelor's, Job Sector: Digital Marketing, Annual Income: $200066.49, Adopter Category: Early Adopter, Tech Interest: High, Technical Proficiency: Intermediate   │     0.874918 │\n",
      "├───────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ TU0873    │ User ID: TU0873, Age: 74, Gender: Male, Location: Crystalport, KS, Education: Some College, Job Sector: Technology, Annual Income: $200009.78, Adopter Category: Early Adopter, Tech Interest: Moderate, Technical Proficiency: Intermediate     │     0.872504 │\n",
      "├───────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ TU0146    │ User ID: TU0146, Age: 56, Gender: Female, Location: Seattle, WA, Education: High School, Job Sector: Data Science, Annual Income: $200038.14, Adopter Category: Early Adopter, Tech Interest: High, Technical Proficiency: Advanced              │     0.872115 │\n",
      "├───────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ TU0066    │ User ID: TU0066, Age: 50, Gender: Non-binary, Location: San Francisco, CA, Education: Bachelor's, Job Sector: Data Science, Annual Income: $200013.7, Adopter Category: Early Adopter, Tech Interest: Very High, Technical Proficiency: Advanced │     0.871491 │\n",
      "╘═══════════╧══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "def run_demo():\n",
    "    # Log model to MLflow\n",
    "    run_id = log_model_to_mlflow()\n",
    "    \n",
    "    if not run_id:\n",
    "        print(\"Model logging failed.\")\n",
    "        return\n",
    "    \n",
    "    # Use a sample query\n",
    "    query = \"Find users with high tech interest who are early adopters of new technologies\"\n",
    "    \n",
    "    try:\n",
    "        # Get similar users based on the query text\n",
    "        similar_users = find_similar_users(\n",
    "            query=query,\n",
    "            run_id=run_id,\n",
    "            top_n=5\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(\"\\nTop similar tech users:\")\n",
    "        print(tabulate(similar_users, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n",
    "        print(\"Displaying sample of the tech dataset instead:\")\n",
    "        tech_df = pd.read_csv(\"data/tech_adoption_dataset.csv\", nrows=5)\n",
    "        print(tabulate(tech_df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "run_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps and Extensions\n",
    "\n",
    "This model could be extended in several ways:\n",
    "\n",
    "1. **Feature Enhancement**:\n",
    "   - Add support for filtering by specific technology categories\n",
    "   - Incorporate product adoption history for more nuanced matching\n",
    "   - Include platform preferences and brand loyalty data\n",
    "\n",
    "2. **Performance Optimization**:\n",
    "   - Use vector databases (like FAISS or Pinecone) for faster similarity search at scale\n",
    "   - Implement batch processing for large user bases\n",
    "\n",
    "3. **User Experience**:\n",
    "   - Develop a more advanced UI with result filtering and sorting\n",
    "   - Add visualizations of user segments\n",
    "   - Implement feedback mechanisms to improve recommendations\n",
    "\n",
    "4. **Integration**:\n",
    "   - Connect with CRM systems for seamless workflow integration\n",
    "   - Set up automated alerts when high-value opportunities are identified\n",
    "   - Create scheduled reports based on specific queries\n",
    "\n",
    "By deploying this system, tech companies can move from static, rule-based user segmentation to dynamic, semantically-rich user discovery that adapts to product managers' specific needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
