{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anHc00I2AtTi"
   },
   "source": [
    "## Banking Scenario\n",
    "\n",
    "\n",
    "Background: First National Bank is implementing an AI-powered system to help relationship managers identify suitable customers for personalized product recommendations. The bank wants to move beyond rule-based targeting (\"all customers over 50 with $100K+ income\") to a more nuanced approach that can understand natural language queries and customer characteristics holistically.\n",
    "\n",
    "Use Case: Relationship managers can use natural language to find customers matching specific profiles or needs. For example, they might search for \"high-income professionals nearing retirement who might be interested in wealth management services\" or \"young professionals with good credit scores who might qualify for premium credit cards.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation Overview\n",
    "\n",
    "This notebook demonstrates how to build and deploy a machine learning model that uses natural language processing to match banking customer profiles with relationship managers' queries. The system leverages:\n",
    "\n",
    "1. **Sentence Transformers**: To convert both customer profiles and natural language queries into semantic vector embeddings\n",
    "2. **MLflow**: For model packaging, versioning, and deployment\n",
    "3. **Semantic Search**: Using cosine similarity to find the most relevant customer matches\n",
    "\n",
    "When deployed, relationship managers can simply type queries like \"Find affluent customers with children in college who might need education loans\" and get a list of the most relevant customers without needing to construct complex database queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR9w8OAnAyM1"
   },
   "source": [
    "## Process Description\n",
    "\n",
    "This Banking Customer Similarity Model provides a semantic search capability over customer profiles. It works by:\n",
    "\n",
    "Data Preparation: Customer data (demographics, financial information, product history) is processed and organized.\n",
    "\n",
    "Embedding Generation: The SentenceTransformer model converts customer profiles into numerical embeddings (high-dimensional vectors) that capture semantic meaning.\n",
    "\n",
    "MLflow Deployment: The model, embeddings, and dataset are packaged and deployed using MLflow for reproducible inference.\n",
    "\n",
    "Query Processing: When a relationship manager enters a natural language query, it's converted to an embedding using the same model.\n",
    "\n",
    "Similarity Matching: The system calculates cosine similarity between the query embedding and all customer embeddings to find the most similar customers.\n",
    "\n",
    "Result Presentation: Top matching customers are presented with their relevant information and similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2Qsxw9tBr3V"
   },
   "source": [
    "## Benefits\n",
    "\n",
    "Personalized Marketing: Target customers with relevant offers based on their profile similarity to successful past campaigns.\n",
    "\n",
    "Risk Assessment: Identify customers with similar risk profiles to known good/bad accounts.\n",
    "\n",
    "Cross-Selling Opportunities: Find customers similar to those who have already purchased specific products.\n",
    "\n",
    "Natural Language Interface: Allows relationship managers to search customers without needing complex SQL queries or predefined segments.\n",
    "\n",
    "Scalability: The system can handle millions of customer profiles efficiently due to the vector-based search approach.\n",
    "\n",
    "This system bridges the gap between rich customer data and actionable insights by providing an intuitive way to explore customer segments and identify targeted opportunities for engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Technical Implementation\n",
    "\n",
    "The following code implements the complete Banking Customer Similarity system. We'll start by importing necessary libraries and setting up our model environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 22:27:53.618837: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 22:27:53.630344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743546473.642509    1263 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743546473.646174    1263 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743546473.655495    1263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743546473.655508    1263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743546473.655509    1263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743546473.655510    1263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-01 22:27:53.659397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Model settings - using local sentence-transformer model\n",
    "model_filename = \"sentence-transformer\"\n",
    "model_dir = \"model\"\n",
    "MODEL_PATH = os.path.join(model_dir, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading\n",
    "\n",
    "First, we define a function to load our sentence transformer model, which will handle the semantic encoding of text. This model converts text into high-dimensional vectors where similar meanings are positioned closer together in the vector space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "The core of our system is the `BankingSimilarityModel` class which:\n",
    "1. Loads pre-computed customer embeddings and banking data\n",
    "2. Handles query encoding and similarity computation\n",
    "3. Formats results for display\n",
    "4. Includes MLflow integration for model deployment\n",
    "\n",
    "This class inherits from `mlflow.pyfunc.PythonModel` to make it deployable through MLflow's model registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banking Similarity Model Class\n",
    "class BankingSimilarityModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        Load precomputed embeddings, banking data, and sentence-transformer model.\n",
    "        \"\"\"\n",
    "        # Load precomputed embeddings\n",
    "        embeddings_path = context.artifacts['embeddings_path']\n",
    "        self.embeddings = np.load(embeddings_path)\n",
    "        \n",
    "        # Load banking dataset\n",
    "        banking_dataset_path = context.artifacts['banking_dataset_path']\n",
    "        self.banking_df = pd.read_csv(banking_dataset_path)\n",
    "        \n",
    "        # Print essential diagnostics\n",
    "        print(f\"Loaded embeddings shape: {self.embeddings.shape}\")\n",
    "        print(f\"Loaded banking data shape: {self.banking_df.shape}\")\n",
    "        \n",
    "        # Load model from artifacts - no fallback needed since we're explicitly including it\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model_path = context.artifacts['model_dir']\n",
    "        self.model = SentenceTransformer(model_path, device=self.device)\n",
    "        print(f\"SentenceTransformer model loaded successfully from {model_path}\")\n",
    "    \n",
    "    def generate_query_embedding(self, query):\n",
    "        \"\"\"Generate embedding for the input query text using SentenceTransformer\"\"\"\n",
    "        # Use mean pooling to get sentence embedding\n",
    "        embedding = self.model.encode(query)\n",
    "        return embedding.reshape(1, -1)  # Reshape to 2D for cosine_similarity\n",
    "    \n",
    "    def predict(self, context, model_input, params):\n",
    "        \"\"\"Find similar banking customers based on semantic similarity to the query text.\"\"\"\n",
    "        try:\n",
    "            # Extract the query string from model input - handle different input types\n",
    "            query = model_input[\"query\"]\n",
    "            if isinstance(query, pd.Series):\n",
    "                query = query.iloc[0]\n",
    "            elif isinstance(query, list):\n",
    "                query = query[0]\n",
    "            \n",
    "            # Convert query to string if it's not already\n",
    "            query = str(query)\n",
    "            print(f\"Processing query: '{query}'\")\n",
    "            \n",
    "            # Extract parameters\n",
    "            top_n = params.get(\"top_n\", 5) if params else 5\n",
    "            \n",
    "            # Check for filtering keywords in query\n",
    "            filter_customers = None\n",
    "            original_query = query\n",
    "            \n",
    "            # Handle credit score filtering\n",
    "            if \"credit score over\" in query.lower() or \"credit score above\" in query.lower():\n",
    "                import re\n",
    "                match = re.search(r'credit score (?:over|above) (\\d+)', query.lower())\n",
    "                if match:\n",
    "                    threshold = int(match.group(1))\n",
    "                    print(f\"Applying filter: Credit Score > {threshold}\")\n",
    "                    filter_customers = self.banking_df['credit_score'] > threshold\n",
    "                    query = re.sub(r'credit score (?:over|above) \\d+', 'good credit score', query)\n",
    "            \n",
    "            # Generate embedding for the query text\n",
    "            query_embedding = self.generate_query_embedding(query)\n",
    "            \n",
    "            # Apply filtering if needed\n",
    "            df_to_search = self.banking_df\n",
    "            embeddings_to_search = self.embeddings\n",
    "            if filter_customers is not None:\n",
    "                filter_indices = np.where(filter_customers)[0]\n",
    "                if len(filter_indices) > 0:\n",
    "                    df_to_search = self.banking_df.iloc[filter_indices]\n",
    "                    embeddings_to_search = self.embeddings[filter_indices]\n",
    "                    print(f\"Filtered to {len(filter_indices)} customers matching criteria\")\n",
    "                else:\n",
    "                    print(\"No customers match the filtering criteria\")\n",
    "                    return {\"predictions\": []}\n",
    "            \n",
    "            # Perform semantic search first to get initial candidates\n",
    "            similarities = cosine_similarity(query_embedding, embeddings_to_search)[0]\n",
    "            top_indices = np.argsort(similarities)[::-1][:min(top_n * 3, len(df_to_search))]  # Get more candidates\n",
    "\n",
    "            # Check for credit score threshold in filtering\n",
    "            credit_score_threshold = None\n",
    "            query_lower = query.lower()\n",
    "            if \"credit score over\" in query_lower or \"credit score above\" in query_lower:\n",
    "                match = re.search(r'credit score (?:over|above) (\\d+)', query_lower)\n",
    "                if match:\n",
    "                    credit_score_threshold = int(match.group(1))\n",
    "                    print(f\"Found explicit credit score threshold: {credit_score_threshold}\")\n",
    "            # Also set a threshold for keyword-based queries\n",
    "            elif any(term in query_lower for term in [\"high credit\", \"good credit\", \"excellent credit\"]):\n",
    "                credit_score_threshold = 700\n",
    "                print(f\"Setting default high credit score threshold: {credit_score_threshold}\")\n",
    "\n",
    "            # Check for income threshold in filtering\n",
    "            income_threshold = None\n",
    "            if \"income over\" in query_lower or \"income above\" in query_lower:\n",
    "                match = re.search(r'income (?:over|above) \\$?(\\d+)', query_lower)\n",
    "                if match:\n",
    "                    income_threshold = int(match.group(1))\n",
    "                    print(f\"Found explicit income threshold: ${income_threshold}\")\n",
    "            # Also set a threshold for keyword-based queries\n",
    "            elif any(term in query_lower for term in [\"high income\", \"wealthy\", \"affluent\", \"rich\"]):\n",
    "                income_threshold = 75000\n",
    "                print(f\"Setting default high income threshold: ${income_threshold}\")\n",
    "\n",
    "            # Apply the boost to the top candidates\n",
    "            top_candidates = df_to_search.iloc[top_indices]\n",
    "            sim_boost = np.zeros(len(top_indices))\n",
    "\n",
    "            # Adjust similarity scores based on numerical criteria\n",
    "            if credit_score_threshold is not None:\n",
    "                credit_scores = top_candidates['credit_score'].values\n",
    "                credit_boost = np.clip((credit_scores - credit_score_threshold) / 100, 0, 0.3)\n",
    "                sim_boost += credit_boost\n",
    "                print(f\"Applying credit score boost up to 0.3 for scores above {credit_score_threshold}\")\n",
    "\n",
    "            if income_threshold is not None:\n",
    "                incomes = top_candidates['income'].values\n",
    "                income_boost = np.clip((incomes - income_threshold) / 50000, 0, 0.3)\n",
    "                sim_boost += income_boost\n",
    "                print(f\"Applying income boost up to 0.3 for income above ${income_threshold}\")\n",
    "\n",
    "            # Apply the boost to the similarities for the top indices\n",
    "            for i, idx in enumerate(top_indices):\n",
    "                similarities[idx] += sim_boost[i]\n",
    "            \n",
    "            # Analyze query for potential sorting criteria\n",
    "            rerank = False\n",
    "            sort_field = None\n",
    "            sort_ascending = False\n",
    "            \n",
    "            # Simple keyword detection - much more generalizable than specific conditions\n",
    "            if any(term in query_lower for term in [\"high credit\", \"good credit\", \"excellent credit\"]):\n",
    "                sort_field = \"credit_score\"\n",
    "                sort_ascending = False\n",
    "                rerank = True\n",
    "            elif any(term in query_lower for term in [\"low credit\", \"poor credit\", \"bad credit\"]):\n",
    "                sort_field = \"credit_score\"\n",
    "                sort_ascending = True\n",
    "                rerank = True\n",
    "            elif any(term in query_lower for term in [\"high income\", \"wealthy\", \"affluent\", \"rich\"]):\n",
    "                sort_field = \"income\"\n",
    "                sort_ascending = False\n",
    "                rerank = True\n",
    "            elif any(term in query_lower for term in [\"low income\", \"budget\"]):\n",
    "                sort_field = \"income\"\n",
    "                sort_ascending = True\n",
    "                rerank = True\n",
    "            \n",
    "            # Apply re-ranking if needed\n",
    "            if rerank and sort_field:\n",
    "                # Create a DataFrame with original indices and similarities\n",
    "                candidates = pd.DataFrame({\n",
    "                    'original_idx': top_indices,\n",
    "                    'similarity': similarities[top_indices]\n",
    "                })\n",
    "                \n",
    "                # Add the sort field values\n",
    "                candidates[sort_field] = df_to_search.iloc[top_indices][sort_field].values\n",
    "                \n",
    "                # Sort by the attribute first, then by similarity\n",
    "                candidates = candidates.sort_values(\n",
    "                    by=[sort_field, 'similarity'], \n",
    "                    ascending=[sort_ascending, False]\n",
    "                )\n",
    "                \n",
    "                # Extract the original indices after sorting\n",
    "                top_indices = candidates['original_idx'].values[:top_n]\n",
    "            else:\n",
    "                # Just take the top semantic matches\n",
    "                top_indices = top_indices[:top_n]\n",
    "            \n",
    "            # Format results (fix the comma issue)\n",
    "            predictions = []\n",
    "            for idx in top_indices:\n",
    "                customer = df_to_search.iloc[idx]\n",
    "                \n",
    "                # Format customer details with correct comma placement\n",
    "                info = f\"Customer ID: {customer['customer_id']}, \"\n",
    "                info += f\"Age: {customer['age']}, \"\n",
    "                info += f\"Income: ${customer['income']:,.2f}, \"  # Add comma here\n",
    "                info += f\"Credit Score: {customer['credit_score']}, \"\n",
    "                info += f\"Segment: {customer['segment']}, \"\n",
    "                info += f\"Risk Profile: {customer['risk_profile']}\"\n",
    "                \n",
    "                # Add to predictions\n",
    "                result = {\n",
    "                    'Customer': info,\n",
    "                    'Similarity': float(similarities[idx])\n",
    "                }\n",
    "                predictions.append(result)\n",
    "            \n",
    "            return {\"predictions\": predictions}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            return {\"predictions\": []}\n",
    "    \n",
    "    @classmethod\n",
    "    def log_model(cls, model_name, embeddings_path, banking_dataset_path, demo_dir=None):\n",
    "        \"\"\"\n",
    "        Logs the model to MLflow with appropriate artifacts and schema.\n",
    "        \"\"\"\n",
    "        # Check if the files exist\n",
    "        for path, desc in [\n",
    "            (embeddings_path, \"Embeddings file\"),\n",
    "            (banking_dataset_path, \"Banking dataset\"),\n",
    "            (MODEL_PATH, \"Model directory\")\n",
    "        ]:\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"{desc} not found: {path}\")\n",
    "        \n",
    "        # Define input/output schemas\n",
    "        input_schema = Schema([ColSpec(\"string\", \"query\")])\n",
    "        output_schema = Schema([\n",
    "            TensorSpec(np.dtype(\"object\"), (-1,), \"predictions\")\n",
    "        ])\n",
    "        params_schema = ParamSchema([\n",
    "            ParamSpec(\"top_n\", \"integer\", 5),\n",
    "            ParamSpec(\"show_score\", \"boolean\", True)\n",
    "        ])\n",
    "        signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=params_schema)\n",
    "        \n",
    "        # Define requirements\n",
    "        requirements = [\n",
    "            \"scikit-learn\", \"pandas\", \"numpy\", \"tabulate\", \n",
    "            \"torch\", \"transformers\", \"sentence-transformers\"\n",
    "        ]\n",
    "        \n",
    "        # Define artifacts - including model directory\n",
    "        artifacts = {\n",
    "            \"embeddings_path\": embeddings_path,\n",
    "            \"banking_dataset_path\": banking_dataset_path,\n",
    "            \"model_dir\": MODEL_PATH\n",
    "        }\n",
    "        \n",
    "        # Add demo directory if provided\n",
    "        if demo_dir and os.path.exists(demo_dir):\n",
    "            artifacts[\"demo\"] = demo_dir\n",
    "            \n",
    "        # Define metadata\n",
    "        metadata = {}\n",
    "        if demo_dir and os.path.exists(os.path.join(demo_dir, \"index.html\")):\n",
    "            metadata[\"demo_template\"] = \"demo/index.html\"\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.pyfunc.log_model(\n",
    "            model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts=artifacts,\n",
    "            signature=signature,\n",
    "            pip_requirements=requirements,\n",
    "            metadata=metadata\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Model Deployment\n",
    "\n",
    "The following function handles the MLflow experiment setup, model logging, and registration. \n",
    "MLflow is used to:\n",
    "- Track experiments and model versions\n",
    "- Package the model with its dependencies and artifacts\n",
    "- Register the model in the Model Registry for deployment\n",
    "- Store the UI components for interactive demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Model to MLflow function\n",
    "def log_model_to_mlflow():\n",
    "    \"\"\"Log the banking similarity model to MLflow.\"\"\"\n",
    "    # Set the MLflow experiment name\n",
    "    experiment_name = \"Banking Customer Similarity\"\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "    \n",
    "    # Check if demo directory exists\n",
    "    demo_dir = \"demo\"\n",
    "    index_html_path = os.path.join(demo_dir, \"index.html\")\n",
    "    \n",
    "    if not os.path.exists(index_html_path):\n",
    "        os.makedirs(demo_dir, exist_ok=True)\n",
    "\n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=\"Banking_Similarity_Run\") as run:\n",
    "        # Log the model\n",
    "        model_name = \"Banking_Customer_Similarity\"\n",
    "        BankingSimilarityModel.log_model(\n",
    "            model_name=model_name,\n",
    "            embeddings_path=\"data/customer_embeddings.npy\",\n",
    "            banking_dataset_path=\"data/banking_dataset.csv\",\n",
    "            demo_dir=demo_dir if os.path.exists(demo_dir) else None\n",
    "        )\n",
    "\n",
    "        # Register the model\n",
    "        registered_model = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{run.info.run_id}/{model_name}\", \n",
    "            name=model_name\n",
    "        )\n",
    "        \n",
    "        print(f\"Registered model: {model_name}, version: {registered_model.version}\")\n",
    "        return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline\n",
    "\n",
    "The `find_similar_customers` function demonstrates how to load our deployed model and use it for inference. This represents what would happen in a production environment when the model is called through an API or application interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Similar Customers function\n",
    "def find_similar_customers(query, run_id=None, top_n=5):\n",
    "    \"\"\"Find similar banking customers for a given query.\"\"\"\n",
    "    # Determine model URI based on run_id\n",
    "    if run_id:\n",
    "        model_uri = f\"runs:/{run_id}/Banking_Customer_Similarity\"\n",
    "    else:\n",
    "        client = MlflowClient()\n",
    "        model_metadata = client.get_latest_versions(\"Banking_Customer_Similarity\", stages=[\"None\"])\n",
    "        latest_model_version = model_metadata[0].version\n",
    "        model_uri = f\"models:/Banking_Customer_Similarity/{latest_model_version}\"\n",
    "    \n",
    "    # Load the model\n",
    "    print(f\"Loading model from: {model_uri}\")\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Run prediction\n",
    "    try:\n",
    "        result = model.predict({\"query\": [query]}, params={\"top_n\": top_n})\n",
    "        \n",
    "        # Extract predictions with proper error handling\n",
    "        if result is None or \"predictions\" not in result:\n",
    "            return pd.DataFrame(columns=[\"Customer\", \"Similarity\"])\n",
    "            \n",
    "        predictions = result.get(\"predictions\", [])\n",
    "        return pd.DataFrame(predictions)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n",
    "        return pd.DataFrame(columns=[\"Customer\", \"Similarity\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo\n",
    "\n",
    "The `run_demo` function shows a complete end-to-end demonstration, from model deployment to customer search. This simulates how a relationship manager would interact with the system in a real banking environment.\n",
    "\n",
    "The demo covers:\n",
    "1. Model deployment to MLflow\n",
    "2. Running a sample query \n",
    "3. Displaying formatted results\n",
    "4. Error handling for failed queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Individual Components\n",
    "\n",
    "The following cells demonstrate how to test individual components of the system for debugging or development purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d61318d88f4cddad94a1018bf9060f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea47d6b73174886b3f0f3c08639cc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc365b87b604ee9970d86c04ffe505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24a22c2e59747fbb3fe06267c724406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Banking_Customer_Similarity' already exists. Creating a new version of this model...\n",
      "Created version '51' of model 'Banking_Customer_Similarity'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model: Banking_Customer_Similarity, version: 51\n",
      "Loading model from: runs:/b196eb3c0a5c42cea62ffaaeb8ea2789/Banking_Customer_Similarity\n",
      "Loaded embeddings shape: (1000, 384)\n",
      "Loaded banking data shape: (1000, 30)\n",
      "SentenceTransformer model loaded successfully from /phoenix/mlflow/470237435216347360/b196eb3c0a5c42cea62ffaaeb8ea2789/artifacts/Banking_Customer_Similarity/artifacts/sentence-transformer\n",
      "Processing query: '['Find high-income customers with excellent credit scores interested in retirement planning']'\n",
      "Setting default high credit score threshold: 700\n",
      "Applying credit score boost up to 0.3 for scores above 700\n",
      "\n",
      "Query: Find high-income customers with excellent credit scores interested in retirement planning\n",
      "\n",
      "Top similar banking customers:\n",
      "╒════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╤══════════════╕\n",
      "│ Customer                                                                                                           │   Similarity │\n",
      "╞════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪══════════════╡\n",
      "│ Customer ID: 645, Age: 55, Income: $103,374.00, Credit Score: 794, Segment: Basic, Risk Profile: Moderate          │     0.797789 │\n",
      "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ Customer ID: 647, Age: 44, Income: $65,286.36, Credit Score: 701, Segment: Senior, Risk Profile: Conservative      │     0.52145  │\n",
      "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ Customer ID: 701, Age: 68, Income: $40,165.97, Credit Score: 690, Segment: Senior, Risk Profile: Very Conservative │     0.505513 │\n",
      "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ Customer ID: 22, Age: 38, Income: $95,928.94, Credit Score: 665, Segment: Senior, Risk Profile: Very Conservative  │     0.499773 │\n",
      "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────┤\n",
      "│ Customer ID: 464, Age: 45, Income: $64,101.54, Credit Score: 665, Segment: Senior, Risk Profile: Very Conservative │     0.498072 │\n",
      "╘════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Run Demo function\n",
    "def run_demo():\n",
    "    \"\"\"Run a complete end-to-end demo.\"\"\"\n",
    "    # Log model\n",
    "    run_id = log_model_to_mlflow()\n",
    "    \n",
    "    if not run_id:\n",
    "        print(\"Model logging failed.\")\n",
    "        return\n",
    "    \n",
    "    # Query\n",
    "    query = \"Find high-income customers with excellent credit scores interested in retirement planning\"\n",
    "    \n",
    "    try:\n",
    "        # Get similar customers\n",
    "        similar_customers = find_similar_customers(query=query, run_id=run_id, top_n=5)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(\"\\nTop similar banking customers:\")\n",
    "        print(tabulate(similar_customers, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n",
    "        print(\"Displaying sample of the banking dataset instead:\")\n",
    "        banking_df = pd.read_csv(\"data/banking_dataset.csv\", nrows=5)\n",
    "        print(tabulate(banking_df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "run_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps and Extensions\n",
    "\n",
    "This model could be extended in several ways:\n",
    "\n",
    "1. **Feature Enhancement**:\n",
    "   - Add support for filtering (e.g., only show customers from specific regions)\n",
    "   - Incorporate transaction history for more nuanced matching\n",
    "   - Include product ownership and interest data\n",
    "\n",
    "2. **Performance Optimization**:\n",
    "   - Use vector databases (like FAISS or Pinecone) for faster similarity search at scale\n",
    "   - Implement batch processing for large customer bases\n",
    "\n",
    "3. **User Experience**:\n",
    "   - Develop a more advanced UI with result filtering and sorting\n",
    "   - Add visualizations of customer segments\n",
    "   - Implement feedback mechanisms to improve recommendations\n",
    "\n",
    "4. **Integration**:\n",
    "   - Connect with CRM systems for seamless workflow integration\n",
    "   - Set up automated alerts when high-value opportunities are identified\n",
    "   - Create scheduled reports based on specific queries\n",
    "\n",
    "By deploying this system, banks can move from static, rule-based customer segmentation to dynamic, semantically-rich customer discovery that adapts to relationship managers' specific needs.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
