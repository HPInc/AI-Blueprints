{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6fbfc8-2cd1-4f92-b1f3-5bbcb2b471b2",
   "metadata": {},
   "source": [
    "# Word Embeddings Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181089eb-c770-45f3-95b7-67e91fa8a7d9",
   "metadata": {},
   "source": [
    "This Jupyter notebook demonstrates how to generate word embeddings from a given corpus using a pre-trained BERT model. These embeddings will be used to find semantically similar matches for a user query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a84a6-5525-4e88-b294-bd9281fded03",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "- Import Dependencies\n",
    "- Configure Logging and Define Constants and Paths\n",
    "- Load and Preprocess Data\n",
    "- Initialize BERT Tokenizer and Model\n",
    "- Generate Embeddings in Batches\n",
    "- Save Embeddings to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992461b-63d7-479e-82fc-28723f297390",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f56c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os  \n",
    "from pathlib import Path  \n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Deep learning framework\n",
    "import torch  \n",
    "\n",
    "# NLP libraries\n",
    "import nltk  # Natural Language Toolkit\n",
    "from nemo.collections.nlp.models import BERTLMModel  # BERT Language Model from NVIDIA NeMo\n",
    "from transformers import AutoTokenizer  # Tokenizer for transformer-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c61ad4-2cdf-443f-b6bc-f26184180536",
   "metadata": {},
   "source": [
    "# Configure Logging and Define Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7602f807-b638-4c44-b228-68a56c0b5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = logging.getLogger(\"notebook_logger\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "                              datefmt=\"%Y-%m-%d %I:%M:%S %p\")  # 12-hour format with AM/PM\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propagate = False\n",
    "\n",
    "CORPUS_PATH = \"../data/raw/corpus.csv\"\n",
    "BERT_MODEL_NAME = \"bert-large-uncased\"\n",
    "BERT_MODEL_DATAFABRIC_PATH = \"/home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo\"\n",
    "EMBEDDINGS_OUTPUT_PATH = \"../data/processed/embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97ae0bc-7bce-4948-9ed4-2ec6d0f4a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 03:34:06 PM - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "logger.info('Notebook execution started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4635eb-9224-4a55-b8c5-a8d519c721c6",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09b9bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Punkt tokenizer data for sentence tokenization\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4414a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 03:34:07 PM - INFO - First few entries of the DataFrame:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Topic                                             Pledge\n",
      "0           0      1  Actually we as an association are still pretty...\n",
      "1           1      1  EFFAT welcomes the Commission Proposal for a R...\n",
      "2           2      1  HOTREC calls for a level playing field and fai...\n",
      "3           3      1  Estonia sees the need to synchronize and harmo...\n",
      "4           4      1  Sphere Travel Club contributes to a flourishin...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "corpus_df = pd.read_csv(CORPUS_PATH)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "logger.info(\"First few entries of the DataFrame:\")\n",
    "print(corpus_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72e3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = corpus_df[\"Pledge\"].astype(str).tolist()  # Convert the column to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b1b05-703e-477c-b68a-9ebcd963df99",
   "metadata": {},
   "source": [
    "# Initialize BERT Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9e6430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd67d5089514557a5a5ead59c2a802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93124cf381a0443aaa02e491e57368cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cbf231a5d24990a53061dd14676d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2068ab249baf42bbbf53c2f678b9be86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 03:34:08 PM - INFO - Loading BERT model...\n",
      "[NeMo W 2025-04-01 15:35:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631440ccde22414593802f25da51c29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-04-01 15:36:04 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-04-01 15:36:04 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-04-01 15:36:04 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-04-01 15:36:06 save_restore_connector:249] Model BERTLMModel was successfully restored from /home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 03:36:06 PM - INFO - BERT model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer with a pre-trained BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logger.info(\"Loading BERT model...\")\n",
    "\n",
    "# Ensure you have added the 'bertlargeuncased' model from the NVIDIA NGC model catalog.\n",
    "# If unavailable, use the alternative method below to download the model online.\n",
    "\n",
    "# Uncomment the following line to download the BERT model online:\n",
    "# bert_model = BERTLMModel.from_pretrained(model_name=\"bertlargeuncased\", strict=False).to(device)\n",
    "\n",
    "# Load the BERT model from a local .nemo file inside datafabric folder\n",
    "bert_model = BERTLMModel.restore_from(BERT_MODEL_DATAFABRIC_PATH, strict=False).to(device)\n",
    "\n",
    "logger.info(\"BERT model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cac586-cea0-4272-b959-d7c0e405e359",
   "metadata": {},
   "source": [
    "# Generate Embeddings in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6010c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_in_batches(texts, tokenizer, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generates text embeddings using the NeMo BERT model in batches.\n",
    "    \n",
    "    Args:\n",
    "        texts (list of str): List of input texts.\n",
    "        tokenizer: Pretrained tokenizer.\n",
    "        model: Pretrained NeMo BERT model.\n",
    "        batch_size (int, optional): Batch size for processing. Default is 32.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Generated embeddings.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize batch with padding and truncation\n",
    "        encoded_input = tokenizer(\n",
    "            batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128\n",
    "        )\n",
    "        encoded_input = {key: val.to(device) for key, val in encoded_input.items()}\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for inference\n",
    "            output = model.bert_model(**encoded_input)\n",
    "        \n",
    "        # Extract the CLS token representation for embeddings\n",
    "        embeddings = output[:, 0, :].cpu().numpy()  # CLS token representation\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c7c77-7a19-469d-8962-862a4b9b7ce7",
   "metadata": {},
   "source": [
    "# Save Embeddings to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03e94c9-6b53-4812-9226-a066896b95cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 03:36:26 PM - INFO - ✅ Embedding completed and saved to: ../data/processed/embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using the pre-trained model\n",
    "embeddings = generate_embeddings_in_batches(documents, tokenizer, bert_model)\n",
    "\n",
    "# Convert embeddings into a DataFrame\n",
    "df_embeddings = pd.DataFrame(embeddings)\n",
    "\n",
    "# Define output file path for saving embeddings\n",
    "df_embeddings.to_csv(EMBEDDINGS_OUTPUT_PATH, index=False)\n",
    "\n",
    "logger.info(f\"✅ Embedding completed and saved to: {EMBEDDINGS_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24a3b99-3081-4559-8130-d8c5a401a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 03:36:26 PM - INFO - Notebook execution completed.\n"
     ]
    }
   ],
   "source": [
    "logger.info('Notebook execution completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
